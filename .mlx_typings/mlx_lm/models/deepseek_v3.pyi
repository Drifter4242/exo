import mlx.core as mx
import mlx.nn as nn
from .base import (
    BaseModelArgs as BaseModelArgs,
    create_attention_mask as create_attention_mask,
    scaled_dot_product_attention as scaled_dot_product_attention,
)
from .pipeline import PipelineMixin as PipelineMixin
from .rope_utils import initialize_rope as initialize_rope
from .switch_layers import SwitchGLU as SwitchGLU
from _typeshed import Incomplete
from dataclasses import dataclass
from functools import partial as partial
from typing import Any

@dataclass
class ModelArgs(BaseModelArgs):
    model_type: str = ...
    vocab_size: int = ...
    hidden_size: int = ...
    intermediate_size: int = ...
    moe_intermediate_size: int = ...
    num_hidden_layers: int = ...
    num_attention_heads: int = ...
    num_key_value_heads: int = ...
    n_shared_experts: int | None = ...
    n_routed_experts: int | None = ...
    routed_scaling_factor: float = ...
    kv_lora_rank: int = ...
    q_lora_rank: int = ...
    qk_rope_head_dim: int = ...
    v_head_dim: int = ...
    qk_nope_head_dim: int = ...
    topk_method: str = ...
    scoring_func: str = ...
    norm_topk_prob: bool = ...
    n_group: int = ...
    topk_group: int = ...
    num_experts_per_tok: int = ...
    moe_layer_freq: int = ...
    first_k_dense_replace: int = ...
    max_position_embeddings: int = ...
    rms_norm_eps: float = ...
    rope_theta: float = ...
    rope_scaling: dict = ...
    attention_bias: bool = ...

class DeepseekV3Attention(nn.Module):
    config: ModelArgs
    hidden_size: int
    num_heads: int
    max_position_embeddings: int
    rope_theta: float
    q_lora_rank: int | None
    qk_rope_head_dim: int
    kv_lora_rank: int
    v_head_dim: int
    qk_nope_head_dim: int
    q_head_dim: int
    scale: float
    q_proj: nn.Linear
    q_a_proj: nn.Linear
    q_a_layernorm: nn.RMSNorm
    q_b_proj: nn.Linear
    kv_a_proj_with_mqa: nn.Linear
    kv_a_layernorm: nn.RMSNorm
    kv_b_proj: nn.Linear
    o_proj: nn.Linear
    rope: Incomplete
    def __init__(self, config: ModelArgs) -> None: ...
    def __call__(
        self, x: mx.array, mask: mx.array | None = None, cache: Any | None = None
    ) -> mx.array: ...

class DeepseekV3MLP(nn.Module):
    config: Incomplete
    hidden_size: Incomplete
    intermediate_size: Incomplete
    gate_proj: nn.Linear
    up_proj: nn.Linear
    down_proj: nn.Linear
    def __init__(
        self, config: ModelArgs, hidden_size: int = None, intermediate_size: int = None
    ) -> None: ...
    def __call__(self, x): ...

@mx.compile
def group_expert_select(
    gates,
    e_score_correction_bias,
    top_k,
    n_group,
    topk_group,
    routed_scaling_factor,
    norm_topk_prob,
): ...

class MoEGate(nn.Module):
    config: Incomplete
    top_k: Incomplete
    norm_topk_prob: Incomplete
    n_routed_experts: Incomplete
    routed_scaling_factor: Incomplete
    n_group: Incomplete
    topk_group: Incomplete
    weight: Incomplete
    e_score_correction_bias: Incomplete
    def __init__(self, config: ModelArgs) -> None: ...
    def __call__(self, x): ...

class DeepseekV3MoE(nn.Module):
    config: Incomplete
    num_experts_per_tok: Incomplete
    switch_mlp: SwitchGLU
    gate: MoEGate
    shared_experts: DeepseekV3MLP
    sharding_group: Incomplete
    def __init__(self, config: ModelArgs) -> None: ...
    def __call__(self, x): ...

class DeepseekV3DecoderLayer(nn.Module):
    self_attn: DeepseekV3Attention
    mlp: DeepseekV3MLP | DeepseekV3MoE
    input_layernorm: nn.RMSNorm
    post_attention_layernorm: nn.RMSNorm
    def __init__(self, config: ModelArgs, layer_idx: int) -> None: ...
    def __call__(
        self, x: mx.array, mask: mx.array | None = None, cache: Any | None = None
    ) -> mx.array: ...

class DeepseekV3Model(PipelineMixin, nn.Module):
    vocab_size: int
    embed_tokens: nn.Embedding
    layers: list[DeepseekV3DecoderLayer]
    norm: nn.RMSNorm
    def __init__(self, config: ModelArgs) -> None: ...
    def __call__(self, x: mx.array, cache: Any | None = None) -> mx.array: ...

class Model(nn.Module):
    args: ModelArgs
    model_type: str
    model: DeepseekV3Model
    lm_head: nn.Linear
    def __init__(self, config: ModelArgs) -> None: ...
    def __call__(self, inputs: mx.array, cache: Any | None = None): ...
    def sanitize(self, weights): ...
    def shard(self, group: mx.distributed.Group | None = None): ...
    @property
    def layers(self) -> list[DeepseekV3DecoderLayer]: ...
    @property
    def cast_predicate(self): ...
